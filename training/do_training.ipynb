{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Python 3.9.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection as fs\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysi = pd.read_csv(\"../datasets/ysi_dataset.csv\")\n",
    "weather = pd.read_csv(\"../datasets/weather_dataset.csv\")\n",
    "# convert to date time and round ysi to nearest 15 mins\n",
    "ysi['datetime'] = pd.to_datetime(ysi['datetime']).dt.round('15min')\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'experimentid_x', 'ph', 'temperature_oc',\n",
       "       'par_umol_photons_m2_s', 'dissolved_oxygen_mg_l', 'airtemp_oc',\n",
       "       'global_light_energy_w_m2', 'humid_rh', 'wdspd_m_s'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both DF's on datetime\n",
    "combined = pd.merge(ysi, weather, on='datetime')\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "combined = combined.drop(columns=['experimentid_y'])\n",
    "combined.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined = combined.drop(combined[combined['ph'] < 5].index)\n",
    "#combined = combined.drop(combined[combined['ph'] > 9].index)\n",
    "combined = combined.drop(combined[combined['dissolved_oxygen_mg_l'] < 2].index)\n",
    "combined = combined.drop(combined[combined['dissolved_oxygen_mg_l'] > 20].index)\n",
    "combined = combined.drop(combined[combined['dissolved_oxygen_mg_l'] < 3/100 * combined['global_light_energy_w_m2']].index)\n",
    "combined = combined.drop(combined[combined['dissolved_oxygen_mg_l'] >( 3/100 * combined['global_light_energy_w_m2']) + 15].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = combined.sample(3000)\n",
    "plt.plot(feat['temperature_oc'],feat['dissolved_oxygen_mg_l'], 'bo')\n",
    "plt.ylabel(\"ph\")\n",
    "plt.xlabel(\"global_light_energy_w_m2\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat[['ph', 'temperature_oc', 'airtemp_oc','global_light_energy_w_m2', 'humid_rh']].values\n",
    "y = feat['dissolved_oxygen_mg_l'].values\n",
    "regressor = RandomForestRegressor(n_estimators=50)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "\n",
    "print(regressor.feature_importances_)\n",
    "\n",
    "model = SelectFromModel(regressor, prefit=True)\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features selected: ph, temperature_oc, global_light_energy_w_m2, humid_rh\n",
    "not considered: wdspd_m_s (low correlation), par_umol_photons_m2_s (duplicated),"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = combined.copy(True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(test[['ph', 'temperature_oc', 'global_light_energy_w_m2', 'humid_rh', 'airtemp_oc']], \n",
    "        test['dissolved_oxygen_mg_l'], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "def stats(y_pred_all, y_test_all):\n",
    "    # Calculate the R2 score\n",
    "    r2 = r2_score(y_test_all, y_pred_all)\n",
    "\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test_all, y_pred_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(y_test_all, y_pred_all, squared=False)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf = make_pipeline(preprocessing.SplineTransformer(), SVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Polynomial SVR Results ------------\")\n",
    "clf = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='poly', shrinking=False, C=2.5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Bagging Results ------------\n",
      "R2 Score: 0.8771\n",
      "Mean Absolute Error (MAE): 0.9105921137685844\n",
      "Root Mean Squared Error (RMSE): 1.2194783131594924\n",
      "------------ Stacking Results ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8643\n",
      "Mean Absolute Error (MAE): 0.9397857931857916\n",
      "Root Mean Squared Error (RMSE): 1.2500593349071598\n"
     ]
    }
   ],
   "source": [
    "print(\"------------ Bagging Results ------------\")\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model = make_pipeline(preprocessing.SplineTransformer(), BaggingRegressor(n_jobs=5))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Stacking Results ------------\")\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "model = StackingRegressor(estimators=[('svr', LinearSVR(random_state=42)), ('rf', RandomForestRegressor(n_estimators=10,random_state=42, n_jobs=8))] )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Random Forest Results ------------\n",
      "R2 Score: 0.8785\n",
      "Mean Absolute Error (MAE): 0.9138361702875165\n",
      "Root Mean Squared Error (RMSE): 1.2160127061818264\n",
      "------------ Poly Regression Results ------------\n",
      "R2 Score: 0.7948\n",
      "Mean Absolute Error (MAE): 1.3693273100484966\n",
      "Root Mean Squared Error (RMSE): 1.3862204378756373\n",
      "------------ Decision Tree Results ------------\n",
      "R2 Score: 0.7730\n",
      "Mean Absolute Error (MAE): 1.0751870775072607\n",
      "Root Mean Squared Error (RMSE): 1.4216622442388305\n",
      "------------ Ada Boost Results ------------\n",
      "R2 Score: 0.7197\n",
      "Mean Absolute Error (MAE): 1.6862719639781343\n",
      "Root Mean Squared Error (RMSE): 1.4985987908783052\n",
      "------------ XG Boost Results ------------\n",
      "R2 Score: 0.8479\n",
      "Mean Absolute Error (MAE): 0.9158081898220805\n",
      "Root Mean Squared Error (RMSE): 1.286283656586761\n"
     ]
    }
   ],
   "source": [
    "print(\"------------ Random Forest Results ------------\")\n",
    "rf_regressor = make_pipeline(preprocessing.SplineTransformer(), RandomForestRegressor(n_estimators=24, max_depth=20))\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Poly Regression Results ------------\")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=5, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "# Initialize and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "# Predict the target variable for training and test sets\n",
    "y_pred = model.predict(X_test_poly)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Decision Tree Results ------------\")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=24)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Ada Boost Results ------------\")\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(learning_rate=0.01, loss='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ XG Boost Results ------------\")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=5, criterion='squared_error')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 16),\n",
    "    nn.CELU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.CELU(),\n",
    "    nn.Linear(16, 4),\n",
    "    nn.CELU(),\n",
    "    nn.Linear(4, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.numeric_columns = ['ph', 'temperature_oc', 'global_light_energy_w_m2']\n",
    "        self.quantile_transformer = preprocessing.PowerTransformer()\n",
    "        transformed_data = self.quantile_transformer.fit_transform(dataframe[self.numeric_columns].values)\n",
    "        dataframe[self.numeric_columns] = transformed_data\n",
    "        self.data = dataframe.dropna(subset=['dissolved_oxygen_mg_l']).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def getInverseTransform(self, inputs):\n",
    "        return self.quantile_transformer.inverse_transform(inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[self.numeric_columns].iloc[idx].values.astype(np.float32)\n",
    "        label = self.data['dissolved_oxygen_mg_l'].iloc[idx].astype(np.float32)\n",
    "        inputs = torch.tensor(inputs)\n",
    "        label = torch.tensor(label)\n",
    "        return inputs, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "test = combined.copy(True)\n",
    "\n",
    "# split testset into training and tetsing\n",
    "trainset, testset = train_test_split(test, test_size=0.3)\n",
    "\n",
    "\n",
    "dataset = MyDataset(trainset)\n",
    "data_loader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over the training batches\n",
    "    for inputs, labels in data_loader:\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "\n",
    "    # Print the loss for each epoch\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Training complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "torch.save(model.state_dict(), './weights/weights2.sav')\n",
    "model.load_state_dict(torch.load('./weights/weights2.sav'))\n",
    "\n",
    "# weights 1 : loss = 30.98\n",
    "# weights 2 : loss = 1.1218"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store true and predicted values\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "newset = pd.merge(ysi, weather, on='datetime').sample(1000)\n",
    "\n",
    "dataset = MyDataset(testset)\n",
    "data_loader = DataLoader(dataset)\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, label in data_loader:\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # Convert the predictions and targets to numpy arrays\n",
    "        y_pred_np = y_pred.numpy()\n",
    "        label_np = label.numpy()\n",
    "        #print(dataset.quantile_transformer.inverse_transform(inputs.numpy()))\n",
    "        #print(f\"actual: { y_pred.item():3f} predicted: {label.item():3f}\")\n",
    "\n",
    "        # Append batch results to the overall lists\n",
    "        y_test_all.append(label_np)\n",
    "        y_pred_all.append(y_pred_np)\n",
    "\n",
    "# Concatenate the lists into a single array\n",
    "y_test_all = np.concatenate(y_test_all)\n",
    "y_pred_all = np.concatenate(y_pred_all)\n",
    "\n",
    "# Calculate the R2 score\n",
    "r2 = r2_score(y_test_all, y_pred_all)\n",
    "\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test_all, y_pred_all)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test_all, y_pred_all, squared=False)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre - Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "play.load_state_dict(torch.load('weights.sav'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import json\n",
    "import io\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = './weights/do_rf.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(regressor, file)\n",
    "\n",
    "# Load the saved model\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Specify the name of the pickle file and the .mar archive file\n",
    "mar_filename = 'model_archive.mar'\n",
    "\n",
    "# Create a new tar archive\n",
    "with tarfile.open(mar_filename, 'w') as archive:\n",
    "    # Add the pickle file to the archive\n",
    "    archive.add(model_filename)\n",
    "\n",
    "# Create a manifest file with the required metadata\n",
    "manifest = {'model-file': model_filename, 'model-name': 'RandomForestRegressor'}\n",
    "\n",
    "# Add the manifest file to the archive\n",
    "with tarfile.open(mar_filename, 'a') as archive:\n",
    "    manifest_string = json.dumps(manifest)\n",
    "    manifest_bytes = manifest_string.encode('utf-8')\n",
    "    manifest_file = tarfile.TarInfo('MANIFEST')\n",
    "    manifest_file.size = len(manifest_bytes)\n",
    "    archive.addfile(manifest_file, io.BytesIO(manifest_bytes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

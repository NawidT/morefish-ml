{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error, f1_score, roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141431\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../../../../../Downloads/UKRiverData.csv\")\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253752"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(\"../../../../../../Downloads/archive.csv\")\n",
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "len(weather)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90393\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['DO_MGL', 'NH4_N_MGL', 'PH', 'NO2_N_MGL'])\n",
    "\n",
    "# Convert 'Date' and 'Time' columns to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# Combine 'Date' and 'Time' columns into 'DateTime' column\n",
    "data['DateTime'] = data['Date'] + pd.to_timedelta(data['Time'].dt.strftime('%H:%M:%S'))\n",
    "data = data.rename(columns={'DateTime': 'time'})\n",
    "data = data.drop_duplicates(subset=['time'])\n",
    "data['time'] = data['time'].dt.round('H')\n",
    "print(len(data))\n",
    "\n",
    "# Remove 'Date' and 'Time' columns if no longer needed\n",
    "data = data.drop(['Site_Code', 'Site_Status_21Oct2020', 'OBJECTID', 'Station_Name', 'RWB_ID_RBP2', 'FESOL1_UGL',\n",
    "                  'P_SOL_MGL', 'SS_MGL','ZN_SOL_UGL', 'GlobalID','Primary_Basin', 'Depth', 'ALK_MGL', 'BOD_MGL', \n",
    "                  'COND_USCM', 'CUSOL1_MGL', 'CUSOL2_UGL', 'Date', 'Time'], axis=1)\n",
    "\n",
    "# Combine the dataframs using merge function\n",
    "weather['time'] = weather['time'].dt.tz_localize('UTC')\n",
    "comb = pd.merge(data, weather, on=['time'], how='left')\n",
    "\n",
    "# Convert our problem to a classification problem\n",
    "comb['decreaseFeed'] = 1\n",
    "comb.loc[comb['NH4_N_MGL'] <= 0.05, 'decreaseFeed'] = 0\n",
    "\n",
    "# Smoothen the data\n",
    "comb = comb.drop(comb[comb['NH4_N_MGL'] < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our problem to a classification problem\n",
    "comb['decreaseFeed'] = 1\n",
    "comb.loc[comb['NH4_N_MGL'] <= 0.15, 'decreaseFeed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# randomly remove rows\\ncondition = comb['NH4_N_MGL'] < 0.2\\n\\n# Randomly select and remove 3 rows that satisfy the condition\\nnum_rows_to_remove = 30000\\nrows_to_remove = comb[condition].sample(n=num_rows_to_remove)\\ncomb = comb[~comb.index.isin(rows_to_remove.index)]\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = comb.drop(comb[comb['NH4_N_MGL'] > 3].index)\n",
    "comb = comb.drop(comb[comb['NH4_N_MGL'] < 0].index)\n",
    "'''\n",
    "# randomly remove rows\n",
    "condition = comb['NH4_N_MGL'] < 0.2\n",
    "\n",
    "# Randomly select and remove 3 rows that satisfy the condition\n",
    "num_rows_to_remove = 30000\n",
    "rows_to_remove = comb[condition].sample(n=num_rows_to_remove)\n",
    "comb = comb[~comb.index.isin(rows_to_remove.index)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79850\n",
      "10150\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = comb.sample(9000)\n",
    "dec = x[x['decreaseFeed'] == 1]\n",
    "print(len(dec) * 10)\n",
    "man = x[x['decreaseFeed'] == 0]\n",
    "print(len(man) * 10)\n",
    "plt.plot(man['NH4_N_MGL'], man['NH4_N_MGL'], 'ro')\n",
    "plt.plot(dec['NH4_N_MGL'], dec['NH4_N_MGL'], 'bo')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23896875 0.207959   0.18023651 0.19303237 0.17980338]\n"
     ]
    }
   ],
   "source": [
    "samp = comb.sample(10000)\n",
    "X = samp[['DO_MGL','PH','temperature_2m (°C)', 'pressure_msl (hPa)', 'diffuse_radiation (W/m²)']].values\n",
    "y = samp['decreaseFeed'].values\n",
    "regressor = RandomForestClassifier(n_estimators=50)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "print(regressor.feature_importances_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split testset into training and tetsing\n",
    "test = cis.copy(True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(test[['DO_MGL','PH','precipitation (mm)','pressure_msl (hPa)', 'direct_radiation (W/m²)']], \n",
    "        test['decreaseFeed'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y_pred, y_test):\n",
    "    # add F1 score, ROC AUC\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"ROC AUC Score: \", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    tp = cm.data[0, 0]\n",
    "    tn = cm.data[0, 1]\n",
    "    fp = cm.data[1, 0]\n",
    "    fn = cm.data[1, 1]\n",
    "\n",
    "    print(\"Precision : \", tp/(tp + tn))\n",
    "    print(\"Recall: \", tp/(tp + fp))\n",
    "    print(\"Accuracy: \", (tp + fn)/(tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.5734518844913054\n",
      "ROC AUC Score:  0.5707071421576654\n",
      "[[3563 2741]\n",
      " [2680 3644]]\n",
      "Precision :  0.5651967005076142\n",
      "Recall:  0.5707192055101714\n",
      "Accuracy:  0.5707158694963573\n",
      "Mean Absolute Error (MAE): 0.4292841305036427\n",
      "Root Mean Squared Error (RMSE): 0.8094428822867059\n"
     ]
    }
   ],
   "source": [
    "# import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), LogisticRegression(random_state=0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Polynomial SVC Results ------\n",
      "F1 Score:  0.5700138352872642\n",
      "ROC AUC Score:  0.5322510912421297\n",
      "[[2809 3495]\n",
      " [2410 3914]]\n",
      "Precision :  0.4455901015228426\n",
      "Recall:  0.538225713738264\n",
      "Accuracy:  0.5323883433639531\n",
      "Mean Absolute Error (MAE): 0.46761165663604687\n",
      "Root Mean Squared Error (RMSE): 0.8269349207180704\n",
      "------ Exponential SVC Results ------\n",
      "F1 Score:  0.6693760984182776\n",
      "ROC AUC Score:  0.5225830732653304\n",
      "[[ 514 5790]\n",
      " [ 230 6094]]\n",
      "Precision :  0.08153553299492386\n",
      "Recall:  0.6908602150537635\n",
      "Accuracy:  0.5232815964523282\n",
      "Mean Absolute Error (MAE): 0.47671840354767187\n",
      "Root Mean Squared Error (RMSE): 0.8309319906542257\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Polynomial SVC Results ------\")\n",
    "clf = make_pipeline(preprocessing.RobustScaler(), NuSVC(kernel='rbf', gamma='auto', degree=3, nu=0.5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Exponential SVC Results ------\")\n",
    "clf = make_pipeline(preprocessing.QuantileTransformer(), SVC(kernel='poly', gamma='auto', degree=9))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Boosting Results ------\n",
      "F1 Score:  0.6149165236386331\n",
      "ROC AUC Score:  0.6091002831048908\n",
      "[[3751 2553]\n",
      " [2383 3941]]\n",
      "Precision :  0.595019035532995\n",
      "Recall:  0.6115096185197261\n",
      "Accuracy:  0.6091225847323408\n",
      "Mean Absolute Error (MAE): 0.3908774152676592\n",
      "Root Mean Squared Error (RMSE): 0.7906970972523976\n",
      "------ Bagging Results ------\n",
      "F1 Score:  0.7867986798679868\n",
      "ROC AUC Score:  0.7954410640955252\n",
      "[[5276 1028]\n",
      " [1556 4768]]\n",
      "Precision :  0.8369289340101523\n",
      "Recall:  0.772248243559719\n",
      "Accuracy:  0.7953753563509661\n",
      "Mean Absolute Error (MAE): 0.2046246436490339\n",
      "Root Mean Squared Error (RMSE): 0.6725730854285915\n",
      "------ Stacking Results ------\n",
      "F1 Score:  0.8112538419103159\n",
      "ROC AUC Score:  0.8103364790324186\n",
      "[[5086 1218]\n",
      " [1177 5147]]\n",
      "Precision :  0.8067893401015228\n",
      "Recall:  0.8120708925435095\n",
      "Accuracy:  0.8103420969274627\n",
      "Mean Absolute Error (MAE): 0.18965790307253722\n",
      "Root Mean Squared Error (RMSE): 0.659922196528531\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Boosting Results ------\")\n",
    "model = make_pipeline(preprocessing.QuantileTransformer(), GradientBoostingClassifier(learning_rate=0.01, max_depth=3, criterion='squared_error'))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Bagging Results ------\")\n",
    "# import Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = make_pipeline(preprocessing.QuantileTransformer(), BaggingClassifier(n_jobs=5, base_estimator=DecisionTreeClassifier(), n_estimators=100))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "\n",
    "print(\"------ Stacking Results ------\")\n",
    "neural = ('nn', make_pipeline(preprocessing.SplineTransformer(), MLPClassifier(hidden_layer_sizes=(16, 32), activation='relu', max_iter=200000)))\n",
    "clf = StackingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(max_depth=24, criterion='entropy', max_features='sqrt')), \n",
    "    ('svm', SVC(kernel='rbf')),\n",
    "    ('gb', GradientBoostingClassifier(max_depth=2))\n",
    "    ])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ KNN Results ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.5824532900081235\n",
      "ROC AUC Score:  0.6747247613635269\n",
      "[[5648  656]\n",
      " [3456 2868]]\n",
      "Precision :  0.8959390862944162\n",
      "Recall:  0.6203866432337434\n",
      "Accuracy:  0.6743744060817232\n",
      "Mean Absolute Error (MAE): 0.32562559391827683\n",
      "Root Mean Squared Error (RMSE): 0.7554046140487042\n",
      "------ Decision Tree Results ------\n",
      "F1 Score:  0.6988279259385086\n",
      "ROC AUC Score:  0.7193043501992249\n",
      "[[4968 1336]\n",
      " [2210 4114]]\n",
      "Precision :  0.7880710659898477\n",
      "Recall:  0.6921147952075787\n",
      "Accuracy:  0.7191954387076338\n",
      "Mean Absolute Error (MAE): 0.2808045612923662\n",
      "Root Mean Squared Error (RMSE): 0.7279491437142798\n",
      "------ Random Forest Results ------\n",
      "F1 Score:  0.796165820088481\n",
      "ROC AUC Score:  0.8030324511088207\n",
      "[[5281 1023]\n",
      " [1465 4859]]\n",
      "Precision :  0.8377220812182741\n",
      "Recall:  0.7828342721612808\n",
      "Accuracy:  0.8029775102945834\n",
      "Mean Absolute Error (MAE): 0.19702248970541653\n",
      "Root Mean Squared Error (RMSE): 0.6662373110880252\n"
     ]
    }
   ],
   "source": [
    "print(\"------ KNN Results ------\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 2 \n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "# Train the kNN classifier\n",
    "knn.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Decision Tree Results ------\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Random Forest Results ------\")\n",
    "clf = RandomForestClassifier(max_depth=40, criterion='gini', max_features='log2')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.numeric_columns = ['PH_DO', 'Pressure_DO', 'RH_DO', 'CloudCover_DO', 'Temp_DO',\n",
    "       'DiffuseRad_DO', 'Precip_DO']\n",
    "        self.transformer = preprocessing.QuantileTransformer()\n",
    "        transformed_data = self.transformer.fit_transform(dataframe[self.numeric_columns].values)\n",
    "        dataframe[self.numeric_columns] = transformed_data\n",
    "        self.data = dataframe.dropna(subset=['NH4_N_MGL']).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def getInverseTransform(self, inputs):\n",
    "        return self.quantile_transformer.inverse_transform(inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[self.numeric_columns].iloc[idx].values.astype(np.float32)\n",
    "        label = self.data['decreaseFeed'].iloc[idx].astype(np.float32)\n",
    "        inputs = torch.tensor(inputs)\n",
    "        label = torch.tensor(label)\n",
    "        return inputs, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(16, 32),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(32, 8),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(8, 1),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reccurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        return tensor[-1, :]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.RNN(input_size=4, hidden_size=32, num_layers=5, batch_first=True, nonlinearity=\"relu\"),\n",
    "    extract_tensor(),\n",
    "    nn.CELU(),\n",
    "    nn.Linear(32, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.LSTM(input_size=4, hidden_size=16, num_layers=7 ,dropout=0.15),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mix of RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.LSTM(input_size=3, hidden_size=8, num_layers=3 ,dropout=0.15),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.CELU(),\n",
    "    nn.RNN(input_size=8, hidden_size=16, num_layers=2, batch_first=True, nonlinearity=\"relu\"),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=32, out_features=8, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Training Loss: 0.1156\n",
      "Epoch 2, Training Loss: 0.1132\n",
      "Epoch 3, Training Loss: 0.1129\n",
      "Epoch 4, Training Loss: 0.1128\n",
      "Epoch 5, Training Loss: 0.1127\n",
      "Epoch 6, Training Loss: 0.1126\n",
      "Epoch 7, Training Loss: 0.1125\n",
      "Epoch 8, Training Loss: 0.1125\n",
      "Epoch 9, Training Loss: 0.1124\n",
      "Epoch 10, Training Loss: 0.1124\n",
      "Epoch 11, Training Loss: 0.1124\n",
      "Epoch 12, Training Loss: 0.1124\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 12\n",
    "\n",
    "test = comb.copy(True)\n",
    "\n",
    "# split testset into training and tetsing\n",
    "trainset, testset = train_test_split(test, test_size=0.15)\n",
    "\n",
    "dataset = MyDataset(trainset)\n",
    "data_loader = DataLoader(dataset, drop_last=True)\n",
    "\n",
    "print(model)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        labels = labels.view(outputs.shape)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        running_loss += abs(loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.4976\n",
      "Mean Absolute Error (MAE): 0.3675807524576835\n",
      "Root Mean Squared Error (RMSE): 0.7786426539146699\n"
     ]
    }
   ],
   "source": [
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "dataset = MyDataset(testset)\n",
    "data_loader = DataLoader(dataset)\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, label in data_loader:\n",
    "        # Forward pass to get predictions\n",
    "        y_pred = model(inputs.unsqueeze(1))\n",
    "        if y_pred <= 0.5:\n",
    "            y_pred_all.append(0)  # Append zero to the list\n",
    "        else:\n",
    "            y_pred_all.append(1)  # Append one to the list\n",
    "        \n",
    "        # Convert the predictions and targets to numpy arrays\n",
    "        label_np = label.numpy()\n",
    "\n",
    "        # Append batch results to the overall lists\n",
    "        y_test_all.append(label_np)\n",
    "\n",
    "# Concatenate the lists into a single array\n",
    "y_test_all = np.array(y_test_all)\n",
    "y_pred_all = np.array(y_pred_all)\n",
    "\n",
    "stats(y_pred_all, y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Interpreter Supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DO_MGL', 'NH4_N_MGL', 'PH', 'relativehumidity_2m (%)',\n",
       "       'pressure_msl (hPa)', 'precipitation (mm)', 'cloudcover (%)',\n",
       "       'direct_radiation (W/m²)', 'decreaseFeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cis = pd.read_csv(\"../datasets/upsampled_data.csv\")\n",
    "cis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def stats(y_pred_all, y_test_all):\n",
    "    # Calculate the R2 score\n",
    "    r2 = r2_score(y_test_all, y_pred_all)\n",
    "\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test_all, y_pred_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(y_test_all, y_pred_all, squared=False)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.to_csv(\"../datasets/combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PH_DO', 'Pressure_DO', 'RH_DO', 'CloudCover_DO', 'Temp_DO',\n",
      "       'DiffuseRad_DO', 'Precip_DO', 'RH_PH', 'RH_Pressure', 'NH4_N_MGL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import missing libraries\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ammData = pd.read_csv(\"../../../../../../Downloads/final_features_short.csv\")\n",
    "\n",
    "# split train and test\n",
    "test = ammData.copy(True)\n",
    "print(test.columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(test[['PH_DO', 'Pressure_DO', 'RH_DO', 'CloudCover_DO', 'Temp_DO',\n",
    "       'DiffuseRad_DO', 'Precip_DO', 'RH_PH', 'RH_Pressure']], test['NH4_N_MGL'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Exponential SVR Results ------------\n",
      "R2 Score: 0.0081\n",
      "Mean Absolute Error (MAE): 0.0678654556140214\n",
      "Root Mean Squared Error (RMSE): 0.4148835345293935\n",
      "------------ Exponential SVR Results ------------\n",
      "R2 Score: -0.0052\n",
      "Mean Absolute Error (MAE): 0.09531670179248984\n",
      "Root Mean Squared Error (RMSE): 0.4162709486940927\n",
      "------------ Polynomial SVR Results ------------\n",
      "R2 Score: 0.0092\n",
      "Mean Absolute Error (MAE): 0.06777841534451286\n",
      "Root Mean Squared Error (RMSE): 0.41477215876243057\n"
     ]
    }
   ],
   "source": [
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf_rbf_nusvm = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf_rbf_nusvm.fit(X_train, y_train)\n",
    "y_pred = clf_rbf_nusvm.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf_rbf_svm = make_pipeline(preprocessing.SplineTransformer(), SVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf_rbf_svm.fit(X_train[:len(X_train)//2], y_train[:len(X_train)//2])\n",
    "clf_rbf_svm.fit(X_train[len(X_train)//2:], y_train[len(X_train)//2:])\n",
    "y_pred = clf_rbf_svm.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Polynomial SVR Results ------------\")\n",
    "clf_poly_nusvm = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='poly', shrinking=False, C=2.5))\n",
    "clf_poly_nusvm.fit(X_train, y_train)\n",
    "y_pred = clf_poly_nusvm.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Random Forest Results ------------\n",
      "R2 Score: -0.0071\n",
      "Mean Absolute Error (MAE): 0.08230576166114743\n",
      "Root Mean Squared Error (RMSE): 0.4164674046051052\n",
      "------------ Poly Regression Results ------------\n",
      "R2 Score: -62623.2676\n",
      "Mean Absolute Error (MAE): 0.4861205345548796\n",
      "Root Mean Squared Error (RMSE): 6.576524712091455\n",
      "------------ Decision Tree Results ------------\n",
      "R2 Score: -1.1275\n",
      "Mean Absolute Error (MAE): 0.10125454058109992\n",
      "Root Mean Squared Error (RMSE): 0.5020887785994078\n",
      "------------ XG Boost Results ------------\n",
      "R2 Score: 0.0387\n",
      "Mean Absolute Error (MAE): 0.0671933902483132\n",
      "Root Mean Squared Error (RMSE): 0.41164394043863345\n"
     ]
    }
   ],
   "source": [
    "print(\"------------ Random Forest Results ------------\")\n",
    "rf_regressor = make_pipeline(preprocessing.StandardScaler(), RandomForestRegressor(n_estimators=24, max_depth=20))\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Poly Regression Results ------------\")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=5, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "# Initialize and fit the linear regression model\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "# Predict the target variable for training and test sets\n",
    "y_pred = poly_reg.predict(X_test_poly)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Decision Tree Results ------------\")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "d_tree = DecisionTreeRegressor(max_depth=24)\n",
    "d_tree.fit(X_train, y_train)\n",
    "y_pred = d_tree.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ XG Boost Results ------------\")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "xg_boost = GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=6, criterion='squared_error')\n",
    "xg_boost.fit(X_train, y_train)\n",
    "y_pred = xg_boost.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Bagging Results ------\n",
      "R2 Score: -0.0967\n",
      "Mean Absolute Error (MAE): 0.0869412525937307\n",
      "Root Mean Squared Error (RMSE): 0.42543690229319614\n",
      "------ Stacking Results ------\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "print(\"------ Bagging Results ------\")\n",
    "bagging = make_pipeline(preprocessing.StandardScaler(), BaggingRegressor(n_estimators=10))\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "stats(y_pred_bagging, y_test)\n",
    "\n",
    "# Stacking\n",
    "print(\"------ Stacking Results ------\")\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = StackingRegressor(estimators=[\n",
    "    ('svr', NuSVR(kernel='poly', shrinking=False, C=2.5)), \n",
    "    ('rf', RandomForestRegressor(n_estimators=10,random_state=42, n_jobs=8)),\n",
    "    ('bag', BaggingRegressor(n_jobs=5)),\n",
    "    ('bst', GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=6, criterion='squared_error')),\n",
    "    ('n1', MLPRegressor(hidden_layer_sizes=(2,3), activation='relu')),\n",
    "    ('n2', MLPRegressor(hidden_layer_sizes=(3,2), activation='tanh'))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "# LinearRegression\n",
    "print(\"------ LinearRegression Results ------\")\n",
    "linear_regression = make_pipeline(preprocessing.StandardScaler(), LinearRegression())\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_pred_lr = linear_regression.predict(X_test)\n",
    "stats(y_pred_lr, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141431\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../../../../../Downloads/UKRiverData.csv\")\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253752"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(\"../../../../../../Downloads/archive.csv\")\n",
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "len(weather)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90393\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['DO_MGL', 'NH4_N_MGL', 'PH', 'NO2_N_MGL'])\n",
    "\n",
    "# Convert 'Date' and 'Time' columns to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# Combine 'Date' and 'Time' columns into 'DateTime' column\n",
    "data['DateTime'] = data['Date'] + pd.to_timedelta(data['Time'].dt.strftime('%H:%M:%S'))\n",
    "data = data.rename(columns={'DateTime': 'time'})\n",
    "data = data.drop_duplicates(subset=['time'])\n",
    "data['time'] = data['time'].dt.round('H')\n",
    "print(len(data))\n",
    "\n",
    "# Remove 'Date' and 'Time' columns if no longer needed\n",
    "data = data.drop(['Site_Code', 'Site_Status_21Oct2020', 'OBJECTID', 'Station_Name', 'RWB_ID_RBP2', 'FESOL1_UGL',\n",
    "                  'P_SOL_MGL', 'SS_MGL','ZN_SOL_UGL', 'GlobalID','Primary_Basin', 'Depth', 'ALK_MGL', 'BOD_MGL', \n",
    "                  'COND_USCM', 'CUSOL1_MGL', 'CUSOL2_UGL', 'Date', 'Time'], axis=1)\n",
    "\n",
    "# Combine the dataframs using merge function\n",
    "weather['time'] = weather['time'].dt.tz_localize('UTC')\n",
    "comb = pd.merge(data, weather, on=['time'], how='left')\n",
    "\n",
    "# Convert our problem to a classification problem\n",
    "comb['decreaseFeed'] = 1\n",
    "comb.loc[comb['NH4_N_MGL'] <= 0.05, 'decreaseFeed'] = 0\n",
    "\n",
    "# Smoothen the data\n",
    "comb = comb.drop(comb[comb['NH4_N_MGL'] < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'DO_MGL', 'NO3_N_MGL', 'NO2_N_MGL', 'NH4_N_MGL', 'PH', 'time',\n",
       "       'temperature_2m (°C)', 'relativehumidity_2m (%)', 'pressure_msl (hPa)',\n",
       "       'precipitation (mm)', 'cloudcover (%)', 'direct_radiation (W/m²)',\n",
       "       'diffuse_radiation (W/m²)', 'decreaseFeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our problem to a classification problem\n",
    "comb['decreaseFeed'] = 1\n",
    "comb.loc[comb['NH4_N_MGL'] <= 0.05, 'decreaseFeed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5732222222222222\n",
      "0.42677777777777776\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = comb.sample(9000)\n",
    "dec = x[x['decreaseFeed'] == 1]\n",
    "print(len(dec)/9000)\n",
    "man = x[x['decreaseFeed'] == 0]\n",
    "print(len(man)/9000)\n",
    "plt.plot(man['NH4_N_MGL'], man['NH4_N_MGL'], 'ro')\n",
    "plt.plot(dec['NH4_N_MGL'], dec['NH4_N_MGL'], 'bo')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23896875 0.207959   0.18023651 0.19303237 0.17980338]\n"
     ]
    }
   ],
   "source": [
    "samp = comb.sample(10000)\n",
    "X = samp[['DO_MGL','PH','temperature_2m (°C)', 'pressure_msl (hPa)', 'diffuse_radiation (W/m²)']].values\n",
    "y = samp['decreaseFeed'].values\n",
    "regressor = RandomForestClassifier(n_estimators=50)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "print(regressor.feature_importances_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split testset into training and tetsing\n",
    "test = comb.copy(True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(test[['DO_MGL','PH','temperature_2m (°C)','pressure_msl (hPa)', 'diffuse_radiation (W/m²)']], \n",
    "        test['decreaseFeed'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y_pred, y_test):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    tp = cm.data[0, 0]\n",
    "    tn = cm.data[0, 1]\n",
    "    fp = cm.data[1, 0]\n",
    "    fn = cm.data[1, 1]\n",
    "\n",
    "    print(\"Precision : \", tp/(tp + tn))\n",
    "    print(\"Recall: \", tp/(tp + fp))\n",
    "    print(\"Accuracy: \", (tp + fn)/(tp + tn + fp + fn))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Polynomial SVC Results ------\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Polynomial SVC Results ------\")\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), SVC(kernel='rbf'))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Exponential SVC Results ------\")\n",
    "clf = make_pipeline(preprocessing.QuantileTransformer(), SVC(kernel='poly'))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Boosting Results ------\n",
      "[[4086 3655]\n",
      " [2097 8241]]\n",
      "Precision :  0.5278387805193128\n",
      "Recall:  0.660844250363901\n",
      "Accuracy:  0.681840809779302\n",
      "Mean Absolute Error (MAE): 0.31815919022069805\n",
      "Root Mean Squared Error (RMSE): 0.7510366282128845\n",
      "------ Bagging Results ------\n",
      "[[4913 2828]\n",
      " [3265 7073]]\n",
      "Precision :  0.634672522929854\n",
      "Recall:  0.6007581315725116\n",
      "Accuracy:  0.6629791470767189\n",
      "Mean Absolute Error (MAE): 0.33702085292328116\n",
      "Root Mean Squared Error (RMSE): 0.7619284555114592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"------ Stacking Results ------\")\\nneural = (\\'nn\\', make_pipeline(preprocessing.SplineTransformer(), MLPClassifier(hidden_layer_sizes=(16, 32), activation=\\'relu\\', max_iter=200000)))\\nclf = StackingClassifier(estimators=[\\n    (\\'rf\\', RandomForestClassifier(max_depth=24, criterion=\\'entropy\\', max_features=\\'sqrt\\')), \\n    (\\'svm\\', SVC(kernel=\\'rbf\\')),\\n    (\\'gb\\', GradientBoostingClassifier(max_depth=2))\\n    ])\\nclf.fit(X_train, y_train)\\ny_pred = clf.predict(X_test)\\nstats(y_pred, y_test)'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"------ Boosting Results ------\")\n",
    "model = make_pipeline(preprocessing.QuantileTransformer(), GradientBoostingClassifier(learning_rate=0.1, max_depth=3, criterion='squared_error'))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Bagging Results ------\")\n",
    "clf = make_pipeline(preprocessing.QuantileTransformer(), BaggingClassifier(n_jobs=5))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "'''\n",
    "print(\"------ Stacking Results ------\")\n",
    "neural = ('nn', make_pipeline(preprocessing.SplineTransformer(), MLPClassifier(hidden_layer_sizes=(16, 32), activation='relu', max_iter=200000)))\n",
    "clf = StackingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(max_depth=24, criterion='entropy', max_features='sqrt')), \n",
    "    ('svm', SVC(kernel='rbf')),\n",
    "    ('gb', GradientBoostingClassifier(max_depth=2))\n",
    "    ])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ KNN Results ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6231 1510]\n",
      " [4581 5757]]\n",
      "Precision :  0.8049347629505232\n",
      "Recall:  0.5763041065482797\n",
      "Accuracy:  0.6630897726644173\n",
      "Mean Absolute Error (MAE): 0.33691022733558273\n",
      "Root Mean Squared Error (RMSE): 0.7618659229116868\n",
      "------ Decision Tree Results ------\n",
      "[[4303 3438]\n",
      " [3222 7116]]\n",
      "Precision :  0.555871334452913\n",
      "Recall:  0.5718272425249169\n",
      "Accuracy:  0.6316167929642126\n",
      "Mean Absolute Error (MAE): 0.36838320703578736\n",
      "Root Mean Squared Error (RMSE): 0.7790672643536529\n",
      "------ Random Forest Results ------\n",
      "[[4627 3114]\n",
      " [2253 8085]]\n",
      "Precision :  0.597726391939026\n",
      "Recall:  0.6725290697674419\n",
      "Accuracy:  0.7031362354112506\n",
      "Mean Absolute Error (MAE): 0.29686376458874936\n",
      "Root Mean Squared Error (RMSE): 0.7381409469231216\n"
     ]
    }
   ],
   "source": [
    "print(\"------ KNN Results ------\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 2 \n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "# Train the kNN classifier\n",
    "knn.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Decision Tree Results ------\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------ Random Forest Results ------\")\n",
    "clf = RandomForestClassifier(max_depth=24, criterion='entropy', max_features='sqrt')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.numeric_columns = ['DO_MGL','PH','temperature_2m (°C)', 'diffuse_radiation (W/m²)']\n",
    "        self.transformer = preprocessing.QuantileTransformer()\n",
    "        transformed_data = self.transformer.fit_transform(dataframe[self.numeric_columns].values)\n",
    "        dataframe[self.numeric_columns] = transformed_data\n",
    "        self.data = dataframe.dropna(subset=['decreaseFeed']).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def getInverseTransform(self, inputs):\n",
    "        return self.quantile_transformer.inverse_transform(inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[self.numeric_columns].iloc[idx].values.astype(np.float32)\n",
    "        label = self.data['decreaseFeed'].iloc[idx].astype(np.float32)\n",
    "        inputs = torch.tensor(inputs)\n",
    "        label = torch.tensor(label)\n",
    "        return inputs, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(16, 32),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(32, 8),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(8, 1),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reccurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        return tensor[-1, :]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.RNN(input_size=4, hidden_size=32, num_layers=5, batch_first=True, nonlinearity=\"relu\"),\n",
    "    extract_tensor(),\n",
    "    nn.CELU(),\n",
    "    nn.Linear(32, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.LSTM(input_size=4, hidden_size=16, num_layers=7 ,dropout=0.15),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mix of RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.LSTM(input_size=3, hidden_size=8, num_layers=3 ,dropout=0.15),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.CELU(),\n",
    "    nn.RNN(input_size=8, hidden_size=16, num_layers=2, batch_first=True, nonlinearity=\"relu\"),\n",
    "    extract_tensor(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LSTM(4, 16, num_layers=7, dropout=0.15)\n",
      "  (1): extract_tensor()\n",
      "  (2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Training Loss: 0.1220\n",
      "Epoch 2, Training Loss: 0.1137\n",
      "Epoch 3, Training Loss: 0.1128\n",
      "Epoch 4, Training Loss: 0.1122\n",
      "Epoch 5, Training Loss: 0.1118\n",
      "Epoch 6, Training Loss: 0.1113\n",
      "Epoch 7, Training Loss: 0.1107\n",
      "Epoch 8, Training Loss: 0.1103\n",
      "Epoch 9, Training Loss: 0.1102\n",
      "Epoch 10, Training Loss: 0.1099\n",
      "Epoch 11, Training Loss: 0.1098\n",
      "Epoch 12, Training Loss: 0.1097\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "num_epochs = 12\n",
    "\n",
    "test = comb.copy(True)\n",
    "\n",
    "# split testset into training and tetsing\n",
    "trainset, testset = train_test_split(test, test_size=0.15)\n",
    "\n",
    "dataset = MyDataset(trainset)\n",
    "data_loader = DataLoader(dataset, drop_last=True)\n",
    "\n",
    "print(model)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        labels = labels.view(outputs.shape)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        running_loss += abs(loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3427 2347]\n",
      " [2367 5418]]\n",
      "Precision :  0.5935226879113267\n",
      "Recall:  0.591473938557128\n",
      "Accuracy:  0.6523342429382698\n",
      "Mean Absolute Error (MAE): 0.3476657570617302\n",
      "Root Mean Squared Error (RMSE): 0.7678749134270801\n"
     ]
    }
   ],
   "source": [
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "dataset = MyDataset(testset)\n",
    "data_loader = DataLoader(dataset)\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, label in data_loader:\n",
    "        # Forward pass to get predictions\n",
    "        y_pred = model(inputs.unsqueeze(1))\n",
    "        if y_pred <= 0.5:\n",
    "            y_pred_all.append(0)  # Append zero to the list\n",
    "        else:\n",
    "            y_pred_all.append(1)  # Append one to the list\n",
    "        \n",
    "        # Convert the predictions and targets to numpy arrays\n",
    "        label_np = label.numpy()\n",
    "\n",
    "        # Append batch results to the overall lists\n",
    "        y_test_all.append(label_np)\n",
    "\n",
    "# Concatenate the lists into a single array\n",
    "y_test_all = np.array(y_test_all)\n",
    "y_pred_all = np.array(y_pred_all)\n",
    "\n",
    "stats(y_pred_all, y_test_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

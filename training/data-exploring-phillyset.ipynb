{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_selection as fs\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205032\n",
      "9720\n"
     ]
    }
   ],
   "source": [
    "phil = pd.read_csv(\"../datasets/Philly/DO_QAQC.csv\")\n",
    "phil['DateTime_EST'] = pd.to_datetime(phil['DateTime_EST'])\n",
    "phil = phil.rename(columns={'DateTime_EST': 'time'}, inplace=False)\n",
    "print(len(phil))\n",
    "\n",
    "philweather = pd.read_csv(\"../datasets/Philly/phillyweather.csv\")\n",
    "philweather['time'] = pd.to_datetime(philweather['time'])\n",
    "print(len(philweather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>DO_mg_L</th>\n",
       "      <th>DO_pct_Sat</th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>Temp_deg_C</th>\n",
       "      <th>DOLoggerType</th>\n",
       "      <th>roundedNearestHour</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relativehumidity_2m (%)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>surface_pressure (hPa)</th>\n",
       "      <th>windspeed_10m (km/h)</th>\n",
       "      <th>direct_radiation (W/m²)</th>\n",
       "      <th>diffuse_radiation (W/m²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 13:00:00</td>\n",
       "      <td>14.72</td>\n",
       "      <td>10.167177</td>\n",
       "      <td>0.250268</td>\n",
       "      <td>14.62</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 13:00:00</td>\n",
       "      <td>19.3</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 13:15:00</td>\n",
       "      <td>14.64</td>\n",
       "      <td>10.189309</td>\n",
       "      <td>0.250425</td>\n",
       "      <td>14.52</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 13:00:00</td>\n",
       "      <td>19.3</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 13:30:00</td>\n",
       "      <td>14.45</td>\n",
       "      <td>10.189309</td>\n",
       "      <td>0.245373</td>\n",
       "      <td>14.52</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 13:45:00</td>\n",
       "      <td>14.51</td>\n",
       "      <td>10.153939</td>\n",
       "      <td>0.239689</td>\n",
       "      <td>14.68</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>14.68</td>\n",
       "      <td>10.110036</td>\n",
       "      <td>0.255636</td>\n",
       "      <td>14.88</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 14:15:00</td>\n",
       "      <td>14.86</td>\n",
       "      <td>10.049144</td>\n",
       "      <td>0.248215</td>\n",
       "      <td>15.16</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 14:30:00</td>\n",
       "      <td>15.01</td>\n",
       "      <td>9.980356</td>\n",
       "      <td>0.251057</td>\n",
       "      <td>15.48</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 14:00:00</td>\n",
       "      <td>18.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 14:45:00</td>\n",
       "      <td>15.01</td>\n",
       "      <td>9.954779</td>\n",
       "      <td>0.247268</td>\n",
       "      <td>15.60</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 15:00:00</td>\n",
       "      <td>17.7</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 15:00:00</td>\n",
       "      <td>15.09</td>\n",
       "      <td>9.937793</td>\n",
       "      <td>0.251373</td>\n",
       "      <td>15.68</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 15:00:00</td>\n",
       "      <td>17.7</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U_A_0</td>\n",
       "      <td>40.20677</td>\n",
       "      <td>-75.29545</td>\n",
       "      <td>2017-04-15 15:15:00</td>\n",
       "      <td>15.09</td>\n",
       "      <td>9.920859</td>\n",
       "      <td>0.252162</td>\n",
       "      <td>15.76</td>\n",
       "      <td>OnsetHOBO</td>\n",
       "      <td>2017-04-15 15:00:00</td>\n",
       "      <td>17.7</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site  Latitude  Longitude                time  DO_mg_L  DO_pct_Sat  \\\n",
       "0  U_A_0  40.20677  -75.29545 2017-04-15 13:00:00    14.72   10.167177   \n",
       "1  U_A_0  40.20677  -75.29545 2017-04-15 13:15:00    14.64   10.189309   \n",
       "2  U_A_0  40.20677  -75.29545 2017-04-15 13:30:00    14.45   10.189309   \n",
       "3  U_A_0  40.20677  -75.29545 2017-04-15 13:45:00    14.51   10.153939   \n",
       "4  U_A_0  40.20677  -75.29545 2017-04-15 14:00:00    14.68   10.110036   \n",
       "5  U_A_0  40.20677  -75.29545 2017-04-15 14:15:00    14.86   10.049144   \n",
       "6  U_A_0  40.20677  -75.29545 2017-04-15 14:30:00    15.01    9.980356   \n",
       "7  U_A_0  40.20677  -75.29545 2017-04-15 14:45:00    15.01    9.954779   \n",
       "8  U_A_0  40.20677  -75.29545 2017-04-15 15:00:00    15.09    9.937793   \n",
       "9  U_A_0  40.20677  -75.29545 2017-04-15 15:15:00    15.09    9.920859   \n",
       "\n",
       "    Depth_m  Temp_deg_C DOLoggerType  roundedNearestHour  temperature_2m (°C)  \\\n",
       "0  0.250268       14.62    OnsetHOBO 2017-04-15 13:00:00                 19.3   \n",
       "1  0.250425       14.52    OnsetHOBO 2017-04-15 13:00:00                 19.3   \n",
       "2  0.245373       14.52    OnsetHOBO 2017-04-15 14:00:00                 18.2   \n",
       "3  0.239689       14.68    OnsetHOBO 2017-04-15 14:00:00                 18.2   \n",
       "4  0.255636       14.88    OnsetHOBO 2017-04-15 14:00:00                 18.2   \n",
       "5  0.248215       15.16    OnsetHOBO 2017-04-15 14:00:00                 18.2   \n",
       "6  0.251057       15.48    OnsetHOBO 2017-04-15 14:00:00                 18.2   \n",
       "7  0.247268       15.60    OnsetHOBO 2017-04-15 15:00:00                 17.7   \n",
       "8  0.251373       15.68    OnsetHOBO 2017-04-15 15:00:00                 17.7   \n",
       "9  0.252162       15.76    OnsetHOBO 2017-04-15 15:00:00                 17.7   \n",
       "\n",
       "   relativehumidity_2m (%)  precipitation (mm)  surface_pressure (hPa)  \\\n",
       "0                       47                 0.0                  1020.0   \n",
       "1                       47                 0.0                  1020.0   \n",
       "2                       52                 0.0                  1020.5   \n",
       "3                       52                 0.0                  1020.5   \n",
       "4                       52                 0.0                  1020.5   \n",
       "5                       52                 0.0                  1020.5   \n",
       "6                       52                 0.0                  1020.5   \n",
       "7                       54                 0.0                  1020.5   \n",
       "8                       54                 0.0                  1020.5   \n",
       "9                       54                 0.0                  1020.5   \n",
       "\n",
       "   windspeed_10m (km/h)  direct_radiation (W/m²)  diffuse_radiation (W/m²)  \n",
       "0                  23.9                      2.0                       3.0  \n",
       "1                  23.9                      2.0                       3.0  \n",
       "2                  23.7                      0.0                       0.0  \n",
       "3                  23.7                      0.0                       0.0  \n",
       "4                  23.7                      0.0                       0.0  \n",
       "5                  23.7                      0.0                       0.0  \n",
       "6                  23.7                      0.0                       0.0  \n",
       "7                  21.7                      0.0                       0.0  \n",
       "8                  21.7                      0.0                       0.0  \n",
       "9                  21.7                      0.0                       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column in philweather called roundedNearestHour and input weather data\n",
    "# time,temperature_2m (°C),relativehumidity_2m (%),precipitation (mm),surface_pressure (hPa),windspeed_10m (km/h),direct_radiation (W/m²),diffuse_radiation (W/m²)\n",
    "phil['roundedNearestHour'] = phil['time'].dt.round('H')\n",
    "phil['temperature_2m (°C)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['temperature_2m (°C)'])\n",
    "phil['relativehumidity_2m (%)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['relativehumidity_2m (%)'])\n",
    "phil['precipitation (mm)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['precipitation (mm)'])\n",
    "phil['surface_pressure (hPa)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['surface_pressure (hPa)'])\n",
    "phil['windspeed_10m (km/h)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['windspeed_10m (km/h)'])\n",
    "phil['direct_radiation (W/m²)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['direct_radiation (W/m²)'])\n",
    "phil['diffuse_radiation (W/m²)'] = phil['roundedNearestHour'].map(philweather.set_index('time')['diffuse_radiation (W/m²)'])\n",
    "\n",
    "\n",
    "phil.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DO_mg_L', 'DO_pct_Sat', 'Depth_m', 'Temp_deg_C', 'temperature_2m (°C)',\n",
       "       'relativehumidity_2m (%)', 'precipitation (mm)',\n",
       "       'surface_pressure (hPa)', 'windspeed_10m (km/h)',\n",
       "       'direct_radiation (W/m²)', 'diffuse_radiation (W/m²)', 'Temp_deg_C^2',\n",
       "       'temperature_2m^2', 'Temp_2m_interaction', 'Depth_Temp_interaction',\n",
       "       'radiation_sum', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf =  pd.read_csv(\"../datasets/Philly/new_features.csv\")\n",
    "nf['time'] = phil['time']\n",
    "\n",
    "nf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(nf[['Temp_deg_C^2', 'temperature_2m^2','Temp_2m_interaction', 'Depth_Temp_interaction', 'Depth_m', 'windspeed_10m (km/h)', 'diffuse_radiation (W/m²)']], nf['DO_mg_L'], test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "def stats(y_pred_all, y_test_all):\n",
    "    # Calculate the R2 score\n",
    "    r2 = r2_score(y_test_all, y_pred_all)\n",
    "\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test_all, y_pred_all)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = mean_squared_error(y_test_all, y_pred_all, squared=False)\n",
    "\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------ Random Forest Results ------------\")\n",
    "rf = RandomForestRegressor(n_estimators=24, max_depth=40, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.feature_importances_)\n",
    "y_pred = rf.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Poly Regression Results ------------\")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=7, include_bias=True)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "# Initialize and fit the linear regression model\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "# Predict the target variable for training and test sets\n",
    "y_pred = poly_reg.predict(X_test_poly)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Decision Tree Results ------------\")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "d_tree = DecisionTreeRegressor(max_depth=24)\n",
    "d_tree.fit(X_train, y_train)\n",
    "y_pred = d_tree.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ XG Boost Results ------------\")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "xg_boost = GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=6, criterion='squared_error')\n",
    "xg_boost.fit(X_train, y_train)\n",
    "y_pred = xg_boost.predict(X_test)\n",
    "stats(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf_rbf_nusvm = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf_rbf_nusvm.fit(X_train, y_train)\n",
    "y_pred = clf_rbf_nusvm.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Exponential SVR Results ------------\")\n",
    "clf_rbf_svm = make_pipeline(preprocessing.SplineTransformer(), SVR(kernel='rbf', shrinking=True, C=1.5))\n",
    "clf_rbf_svm.fit(X_train[:len(X_train)//2], y_train[:len(X_train)//2])\n",
    "clf_rbf_svm.fit(X_train[len(X_train)//2:], y_train[len(X_train)//2:])\n",
    "y_pred = clf_rbf_svm.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Polynomial SVR Results ------------\")\n",
    "clf_poly_nusvm = make_pipeline(preprocessing.SplineTransformer(), NuSVR(kernel='poly', shrinking=False, C=2.5))\n",
    "clf_poly_nusvm.fit(X_train, y_train)\n",
    "y_pred = clf_poly_nusvm.predict(X_test)\n",
    "stats(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------ Bagging Results ------------\")\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "bag_pipe = make_pipeline(preprocessing.SplineTransformer(), BaggingRegressor(base_estimator=base_estimator, n_estimators=10, n_jobs=5))\n",
    "bag_pipe.fit(X_train, y_train)\n",
    "y_pred = bag_pipe.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Extra Trees Results ------------\")\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "extra_pipe = make_pipeline(preprocessing.SplineTransformer(), ExtraTreesRegressor(n_estimators=10, n_jobs=5))\n",
    "extra_pipe.fit(X_train, y_train)\n",
    "y_pred = extra_pipe.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "print(\"------------ Ada Boost Results ------------\")\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_pipe = make_pipeline(preprocessing.SplineTransformer(), AdaBoostRegressor(base_estimator=base_estimator, n_estimators=10))\n",
    "ada_pipe.fit(X_train, y_train)\n",
    "y_pred = ada_pipe.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "'''\n",
    "print(\"------------ Voting Results ------------\")\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "voting_pipe = make_pipeline(preprocessing.SplineTransformer(), VotingRegressor(estimators=[\n",
    "    ('svr', NuSVR(kernel='poly', shrinking=False, C=2.5)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=10,random_state=42, n_jobs=8)),\n",
    "    ('bag', BaggingRegressor(n_jobs=5)),\n",
    "    ('bst', GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=6, criterion='squared_error')),\n",
    "    ('n1', MLPRegressor(hidden_layer_sizes=(2,3), activation='relu')),  \n",
    "    ('n2', MLPRegressor(hidden_layer_sizes=(3,2), activation='tanh'))\n",
    "]))\n",
    "voting_pipe.fit(X_train, y_train)\n",
    "y_pred = voting_pipe.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "\n",
    "\n",
    "print(\"------------ Stacking Results ------------\")\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "model = StackingRegressor(estimators=[\n",
    "    ('svr', NuSVR(kernel='poly', shrinking=False, C=2.5)), \n",
    "    ('rf', RandomForestRegressor(n_estimators=10,random_state=42, n_jobs=8)),\n",
    "    ('bag', BaggingRegressor(n_jobs=5)),\n",
    "    ('bst', GradientBoostingRegressor(learning_rate=0.1, loss='huber', max_depth=6, criterion='squared_error')),\n",
    "    ('n1', MLPRegressor(hidden_layer_sizes=(2,3), activation='relu')),\n",
    "    ('n2', MLPRegressor(hidden_layer_sizes=(3,2), activation='tanh'))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "stats(y_pred, y_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(\n",
    "    host='localhost', \n",
    "    user='root', \n",
    "    password='N@wid2003', \n",
    "    db='dma_iot_morefish_spark_farms_v3'\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Get the latest data from the database and store it in a pandas dataframe\n",
    "query = \"SELECT dvd_ph, dvd_temp, dvd_updated_at, dvd_do FROM device_devicedata WHERE dvd_ph > 0 AND dvd_temp > 0 AND dvd_dev_id = 2 ORDER BY dvd_updated_at ASC\"\n",
    "df = pd.read_sql(query, connection)\n",
    "\n",
    "# Close the connection\n",
    "connection.close()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'dvd_ph': 'ph', 'dvd_temp': 'temperature', 'dvd_updated_at': 'datetime', 'dvd_do': 'do_linreg'}, inplace=True)\n",
    "df['rounded_datetime'] = pd.to_datetime(df['datetime']).dt.round('H')\n",
    "# spark_weather = pd.read_csv(\"../../../../../../Downloads/sparkfarmsweather.csv\")\n",
    "spark_weather = pd.read_csv(\"../datasets/sparkfarmsweather.csv\")\n",
    "spark_weather['time'] = pd.to_datetime(spark_weather['time'])\n",
    "spark_weather.rename(columns={'time': 'datetime'}, inplace=True)\n",
    "# Merge the weather data with the main DataFrame based on 'rounded_datetime' column\n",
    "df = df.merge(spark_weather, left_on='rounded_datetime', right_on='datetime', how='left')\n",
    "df = df.drop(columns=['datetime_y'])\n",
    "df.rename(columns={'datetime_x': 'datetime', 'diffuse_radiation (W/m²)': 'light', 'relativehumidity_2m (%)': 'humid', 'temperature_2m (°C)': 'airtemp' }, inplace=True)\n",
    "# drop all NaN values inside diffuse radiation\n",
    "df = df.dropna(subset=['light'])\n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
